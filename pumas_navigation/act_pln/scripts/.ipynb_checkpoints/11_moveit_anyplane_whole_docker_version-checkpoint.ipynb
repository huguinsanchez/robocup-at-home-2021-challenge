{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "ja"
   },
   "source": [
    "必要なライブラリをインポートして、初期化を行います。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "Import the required libraries and initialize them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import ros_numpy\n",
    "import rospy\n",
    "import tf\n",
    "from gazebo_ros import gazebo_interface\n",
    "from sensor_msgs.msg import LaserScan, PointCloud2\n",
    "from geometry_msgs.msg import Pose, Quaternion ,TransformStamped,PoseStamped\n",
    "import tf2_ros\n",
    "import sys\n",
    "\n",
    "from utils import *\n",
    "import cv2\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting job # 0 in a separate thread.\n"
     ]
    }
   ],
   "source": [
    "%%script bash --bg\n",
    "rviz -d data/3_navigation.rviz > /dev/null 2>&1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##KNOWN LOCATIONS\n",
    "kl_mess1= [1.04,0.3,90]\n",
    "kl_table1= [1.04,1.3,90]\n",
    "kl_tray=  [ -0.04168256822546347, 1.5,-90]\n",
    "kl_box1=  [-0.04168256822546347, 2.427268271720426, -90]\n",
    "### ARM \n",
    "arm_grasp_from_above=[0.19263830140116414,\n",
    " -2.2668981568652917,\n",
    " -0.007358947463759424,\n",
    " -0.9939144210462025,\n",
    " -0.17365421548386273,\n",
    " 0.0]\n",
    "arm_grasp_from_above_table=[0.41349380130577407,\n",
    " -1.671584191489468,\n",
    " -0.02774372779356371,\n",
    " -1.5952436225825641,\n",
    " 0.22362492457833927,\n",
    " 0.0]\n",
    "\n",
    "\n",
    "arm_grasp_table=[0.41349380130577407,\n",
    " -1.671584191489468,\n",
    " -0.02774372779356371,\n",
    " 0.0,\n",
    " 0.22362492457833927,\n",
    " 0.0]\n",
    "\n",
    "\n",
    "arm_grasp_floor=[-1.5151551103007697e-05,\n",
    " -2.4,\n",
    " -0.2620865401925543,\n",
    " 0.7019536624449207,\n",
    " 0.20120924571306453,\n",
    " 0.0]\n",
    "arm_train_pose=[0.033749214744071214,\n",
    " -2.1204421063180217,\n",
    " -1.3982377978814715,\n",
    " -1.7296544561013807,\n",
    " 2.135675364707808,\n",
    " 0.0]\n",
    "\n",
    "arm_ready_to_place=[0.03999320441056991,\n",
    " -0.4729690540086997,\n",
    " 0.19361475012179108,\n",
    " -1.5269847787383313,\n",
    " -0.009753879176134461,\n",
    " 0.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_table2(chan):\n",
    "    image_data=rgbd.get_image()\n",
    "    points_data = rgbd.get_points()\n",
    "\n",
    "    mask=np.zeros((image_data.shape))\n",
    "    plane_mask=np.zeros((image_data.shape[0],image_data.shape[1]))\n",
    "\n",
    "    plane_mask=image_data[:,:,chan]\n",
    "\n",
    "    ret,thresh = cv2.threshold(image_data[:,:,2],240,255,200)\n",
    "    plane_mask=points_data['z']\n",
    "    cv2_img=plane_mask.astype('uint8')\n",
    "    img=image_data[:,:,0]\n",
    "    _,contours, hierarchy = cv2.findContours(thresh.astype('uint8'),cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    i=0\n",
    "    cents=[]\n",
    "    for i, contour in enumerate(contours):\n",
    "        area = cv2.contourArea(contour)\n",
    "\n",
    "        if area > 200 and area < 50000 :\n",
    "            print('contour',i,'area',area)\n",
    "\n",
    "            boundRect = cv2.boundingRect(contour)\n",
    "            #just for drawing rect, dont waste too much time on this\n",
    "            print boundRect\n",
    "            img=cv2.rectangle(img,(boundRect[0], boundRect[1]),(boundRect[0]+boundRect[2], boundRect[1]+boundRect[3]), (0,0,0), 2)\n",
    "            # calculate moments for each contour\n",
    "            xyz=[]\n",
    "\n",
    "\n",
    "            for jy in range (boundRect[0], boundRect[0]+boundRect[2]):\n",
    "                for ix in range(boundRect[1], boundRect[1]+boundRect[3]):\n",
    "                    xyz.append(np.asarray((points_data['x'][ix,jy],points_data['y'][ix,jy],points_data['z'][ix,jy])))\n",
    "            xyz=np.asarray(xyz)\n",
    "            cent=xyz.mean(axis=0)\n",
    "            cents.append(cent)\n",
    "            M = cv2.moments(contour)\n",
    "            # calculate x,y coordinate of center\n",
    "            cX = int(M[\"m10\"] / M[\"m00\"])\n",
    "            cY = int(M[\"m01\"] / M[\"m00\"])\n",
    "            cv2.circle(img, (cX, cY), 5, (255, 255, 255), -1)\n",
    "            cv2.putText(img, \"centroid_\"+str(i)+\"_\"+str(cX)+','+str(cY)    ,    (cX - 25, cY - 25)   ,cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 0, 0), 2)\n",
    "            print ('cX,cY',cX,cY)\n",
    "    cents=np.asarray(cents)\n",
    "    plt.imshow(img )\n",
    "    return (cents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_table():\n",
    "    image_data=rgbd.get_image()\n",
    "    points_data = rgbd.get_points()\n",
    "\n",
    "    mask=np.zeros((image_data.shape))\n",
    "    plane_mask=np.zeros((image_data.shape[0],image_data.shape[1]))\n",
    "\n",
    "    plane_mask=image_data[:,:,1]\n",
    "\n",
    "    ret,thresh = cv2.threshold(image_data[:,:,2],240,255,200)\n",
    "    plane_mask=points_data['z']\n",
    "    cv2_img=plane_mask.astype('uint8')\n",
    "    img=image_data[:,:,0]\n",
    "    _,contours, hierarchy = cv2.findContours(thresh.astype('uint8'),cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    i=0\n",
    "    cents=[]\n",
    "    for i, contour in enumerate(contours):\n",
    "        area = cv2.contourArea(contour)\n",
    "\n",
    "        if area > 2000 and area < 50000 :\n",
    "            print('contour',i,'area',area)\n",
    "\n",
    "            boundRect = cv2.boundingRect(contour)\n",
    "            #just for drawing rect, dont waste too much time on this\n",
    "            print boundRect\n",
    "            img=cv2.rectangle(img,(boundRect[0], boundRect[1]),(boundRect[0]+boundRect[2], boundRect[1]+boundRect[3]), (0,0,0), 2)\n",
    "            # calculate moments for each contour\n",
    "            xyz=[]\n",
    "\n",
    "\n",
    "            for jy in range (boundRect[0], boundRect[0]+boundRect[2]):\n",
    "                for ix in range(boundRect[1], boundRect[1]+boundRect[3]):\n",
    "                    xyz.append(np.asarray((points_data['x'][ix,jy],points_data['y'][ix,jy],points_data['z'][ix,jy])))\n",
    "            xyz=np.asarray(xyz)\n",
    "            cent=xyz.mean(axis=0)\n",
    "            cents.append(cent)\n",
    "            M = cv2.moments(contour)\n",
    "            # calculate x,y coordinate of center\n",
    "            cX = int(M[\"m10\"] / M[\"m00\"])\n",
    "            cY = int(M[\"m01\"] / M[\"m00\"])\n",
    "            cv2.circle(img, (cX, cY), 5, (255, 255, 255), -1)\n",
    "            cv2.putText(img, \"centroid_\"+str(i)+\"_\"+str(cX)+','+str(cY)    ,    (cX - 25, cY - 25)   ,cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 0, 0), 2)\n",
    "            print ('cX,cY',cX,cY)\n",
    "    cents=np.asarray(cents)\n",
    "    plt.imshow(img )\n",
    "    return (cents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_floor():\n",
    "        image_data=rgbd.get_image()\n",
    "        points_data = rgbd.get_points()\n",
    "\n",
    "##### WILL PACKAGE IT BETTER SOON I PROMISE######################################################################\n",
    "        ##px pixels /2D world  P1 3D world\n",
    "        px_y,px_x=-1,-200\n",
    "        P1= np.asarray((points_data[px_y,px_x]['x'],points_data[px_y,px_x]['y'],points_data[px_y,px_x]['z'] ))\n",
    "        px_y,px_x=-1,200\n",
    "        P2= np.asarray((points_data[px_y,px_x]['x'],points_data[px_y,px_x]['y'],points_data[px_y,px_x]['z'] ))\n",
    "        px_y,px_x=-150,320\n",
    "        P3= np.asarray((points_data[px_y,px_x]['x'],points_data[px_y,px_x]['y'],points_data[px_y,px_x]['z'] ))\n",
    "        #      \n",
    "\n",
    "        V1 =P1 - P2\n",
    "        V2= P3-P2\n",
    "        nx,ny,nz=np.cross(V2,V1)\n",
    "        print('look at the phi angle  in normal vector', np.rad2deg(cart2spher(nx,ny,nz))[2]-90)\n",
    "        trans , rot = listener.lookupTransform('/map', '/head_rgbd_sensor_gazebo_frame', rospy.Time(0))\n",
    "        euler=tf.transformations.euler_from_quaternion(rot)\n",
    "        print(   np.rad2deg(euler)[1],'if this degree is not the same as head tilt plane was not found')\n",
    "        \n",
    "        mask=np.zeros((image_data.shape))\n",
    "        plane_mask=np.zeros((image_data.shape[0],image_data.shape[1]))\n",
    "        mask[:,:,0]=points_data['x'] - P1[0]\n",
    "        mask[:,:,1]=points_data['y'] - P1[1]\n",
    "        mask[:,:,2]=points_data['z'] - P1[2]\n",
    "        for i in range (image_data.shape[0]):\n",
    "            for j in range (image_data.shape[1]):\n",
    "                plane_mask[i,j]=-np.dot(np.asarray((nx,ny,nz,)),mask[i,j])\n",
    "        plane_mask=plane_mask-np.min(plane_mask)\n",
    "        plane_mask=plane_mask*256/np.max(plane_mask)\n",
    "        plane_mask.astype('uint8')\n",
    "\n",
    "        ret,thresh = cv2.threshold(plane_mask,3,255,0)\n",
    "\n",
    "        cv2_img=plane_mask.astype('uint8')\n",
    "        img=plane_mask.astype('uint8')\n",
    "        _,contours, hierarchy = cv2.findContours(thresh.astype('uint8'),cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "        i=0\n",
    "        cents=[]\n",
    "        for i, contour in enumerate(contours):\n",
    "            area = cv2.contourArea(contour)\n",
    "            \n",
    "            if area > 200 and area < 50000 :\n",
    "                #print('contour',i,'area',area)\n",
    "                \n",
    "                boundRect = cv2.boundingRect(contour)\n",
    "                #just for drawing rect, dont waste too much time on this\n",
    "                img=cv2.rectangle(img,(boundRect[0], boundRect[1]),(boundRect[0]+boundRect[2], boundRect[1]+boundRect[3]), (255,0,0), 2)\n",
    "                # calculate moments for each contour\n",
    "                xyz=[]\n",
    "                \n",
    "                \n",
    "                for jy in range (boundRect[0], boundRect[0]+boundRect[2]):\n",
    "                    for ix in range(boundRect[1], boundRect[1]+boundRect[3]):\n",
    "                        xyz.append(np.asarray((points_data['x'][ix,jy],points_data['y'][ix,jy],points_data['z'][ix,jy])))\n",
    "                xyz=np.asarray(xyz)\n",
    "                cent=xyz.mean(axis=0)\n",
    "                cents.append(cent)\n",
    "                M = cv2.moments(contour)\n",
    "                # calculate x,y coordinate of center\n",
    "                cX = int(M[\"m10\"] / M[\"m00\"])\n",
    "                cY = int(M[\"m01\"] / M[\"m00\"])\n",
    "                cv2.circle(img, (cX, cY), 5, (255, 255, 255), -1)\n",
    "                cv2.putText(img, \"centroid_\"+str(i)+\"_\"+str(cX)+','+str(cY)    ,    (cX - 25, cY - 25)   ,cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 255, 255), 2)\n",
    "        cents=np.asarray(cents)\n",
    "        plt.imshow(img)\n",
    "        return cents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def publish_scene():\n",
    "\n",
    "    p = PoseStamped()\n",
    "    p.header.frame_id =\"map\"# \"head_rgbd_sensor_link\"\n",
    "    big_table_size = [1.7, 0.13, .7]\n",
    "    p.pose.position.x = 0.95\n",
    "    p.pose.position.y = 1.9\n",
    "    p.pose.position.z = 0.34\n",
    "\n",
    "    p.pose.orientation.x= 0.5*np.pi\n",
    "    p.pose.orientation.w= 0.5*np.pi\n",
    "\n",
    "    scene.add_box(\"table_big\",p,big_table_size)\n",
    "\n",
    "    p = PoseStamped()\n",
    "    p.header.frame_id =\"map\"# \"head_rgbd_sensor_link\"\n",
    "    table_small_size = [0.5, 0.01, .4]\n",
    "    p.pose.position.x = .1\n",
    "    p.pose.position.y = 1.9\n",
    "    p.pose.position.z = 0.61\n",
    "    p.pose.orientation.x= 0.5*np.pi\n",
    "    p.pose.orientation.w= 0.5*np.pi\n",
    "\n",
    "    scene.add_box(\"table_small\",p,table_small_size)\n",
    "\n",
    "    p = PoseStamped()\n",
    "    p.header.frame_id =\"map\"# \"head_rgbd_sensor_link\"\n",
    "    table_tray_size = [0.65, 0.01, .7]\n",
    "    p.pose.position.x = 1.8\n",
    "    p.pose.position.y = -0.65\n",
    "    p.pose.position.z = 0.4\n",
    "    p.pose.orientation.x= 0.5*np.pi\n",
    "    p.pose.orientation.w= 0.5*np.pi\n",
    "    scene.add_box(\"table_tray\",p,table_tray_size)\n",
    "    return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TF WRT HEAD SENSOR\n",
    "def static_tf_publish(cents):\n",
    "    for  i ,cent  in enumerate(cents):\n",
    "        x,y,z=cent\n",
    "        broadcaster.sendTransform((x,y,z),rot, rospy.Time.now(), 'Closest_Object'+str(i),\"head_rgbd_sensor_link\")\n",
    "        rospy.sleep(.2)\n",
    "        xyz_map,cent_quat= listener.lookupTransform('/map', 'Closest_Object'+str(i),rospy.Time(0))\n",
    "        map_euler=tf.transformations.euler_from_quaternion(cent_quat)\n",
    "        rospy.sleep(.2)\n",
    "        static_transformStamped = TransformStamped()\n",
    "\n",
    "        ##FIXING TF TO MAP ( ODOM REALLY)    \n",
    "        #tf_broadcaster1.sendTransform( (xyz[0],xyz[1],xyz[2]),tf.transformations.quaternion_from_euler(0, 0, 0), rospy.Time.now(), \"obj\"+str(ind), \"head_rgbd_sensor_link\")\n",
    "        static_transformStamped.header.stamp = rospy.Time.now()\n",
    "        static_transformStamped.header.frame_id = \"map\"\n",
    "        static_transformStamped.child_frame_id = \"static\"+str(i)\n",
    "        static_transformStamped.transform.translation.x = float(xyz_map[0])\n",
    "        static_transformStamped.transform.translation.y = float(xyz_map[1])\n",
    "        static_transformStamped.transform.translation.z = float(xyz_map[2])\n",
    "        #quat = tf.transformations.quaternion_from_euler(-euler[0],0,1.5)\n",
    "        static_transformStamped.transform.rotation.x = 0#-quat[0]#trans.transform.rotation.x\n",
    "        static_transformStamped.transform.rotation.y = 0#-quat[1]#trans.transform.rotation.y\n",
    "        static_transformStamped.transform.rotation.z = 0#-quat[2]#trans.transform.rotation.z\n",
    "        static_transformStamped.transform.rotation.w = 1#-quat[3]#trans.transform.rotation.w\n",
    "\n",
    "\n",
    "        tf_static_broadcaster.sendTransform(static_transformStamped)\n",
    "    return True\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cart2spher(x,y,z):\n",
    "    ro= np.sqrt(x**2+y**2+z**2)\n",
    "    th=np.arctan2(y,x)\n",
    "    phi=np.arctan2((np.sqrt(x**2+y**2)),z)\n",
    "    return np.asarray((ro,th,phi))\n",
    "def spher2cart(ro,th,phi):\n",
    "    x= ro * np.cos(th)* np.sin(phi)\n",
    "    y= ro * np.sin(th)* np.sin(phi)\n",
    "    z= ro*  np.cos(th)\n",
    "    return np.asarray((x,y,z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rospy.init_node(\"recognition\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "listener = tf.TransformListener()\n",
    "broadcaster= tf.TransformBroadcaster()\n",
    "tf_static_broadcaster= tf2_ros.StaticTransformBroadcaster()\n",
    "import moveit_commander\n",
    "import moveit_msgs.msg\n",
    "###might take some time to load all those takeshi meshes in rviz\n",
    "\n",
    "head = moveit_commander.MoveGroupCommander('head')\n",
    "arm = moveit_commander.MoveGroupCommander('arm')\n",
    "whole_body = moveit_commander.MoveGroupCommander('whole_body_light')\n",
    "whole_body.set_workspace([-6.0, -6.0, 6.0, 6.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "ja"
   },
   "source": [
    "rvizを起動します．ロボットモデル、カメラ映像、ポイントクラウドが表示されています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Image data cannot be converted to float",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-ac53058557fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mrgbd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRGBD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrgbd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/matplotlib/pyplot.pyc\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, hold, data, **kwargs)\u001b[0m\n\u001b[1;32m   3208\u001b[0m                         \u001b[0mfilternorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilternorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilterrad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilterrad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3209\u001b[0m                         \u001b[0mimlim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimlim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3210\u001b[0;31m                         **kwargs)\n\u001b[0m\u001b[1;32m   3211\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3212\u001b[0m         \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwashold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/matplotlib/__init__.pyc\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1868\u001b[0m                         \u001b[0;34m\"the Matplotlib list!)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlabel_namer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1869\u001b[0m                         RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1870\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1872\u001b[0m         inner.__doc__ = _add_data_doc(inner.__doc__,\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/matplotlib/axes/_axes.pyc\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, **kwargs)\u001b[0m\n\u001b[1;32m   5499\u001b[0m                               resample=resample, **kwargs)\n\u001b[1;32m   5500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5501\u001b[0;31m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5502\u001b[0m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_alpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5503\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_clip_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/matplotlib/image.pyc\u001b[0m in \u001b[0;36mset_data\u001b[0;34m(self, A)\u001b[0m\n\u001b[1;32m    640\u001b[0m         if (self._A.dtype != np.uint8 and\n\u001b[1;32m    641\u001b[0m                 not np.can_cast(self._A.dtype, float, \"same_kind\")):\n\u001b[0;32m--> 642\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Image data cannot be converted to float\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    643\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m         if not (self._A.ndim == 2\n",
      "\u001b[0;31mTypeError\u001b[0m: Image data cannot be converted to float"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "rgbd = RGBD()\n",
    "x=rgbd.get_image()\n",
    "plt.imshow(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene = moveit_commander.PlanningSceneInterface()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_pub = rospy.Publisher('planning_scene',\n",
    "                                         moveit_msgs.msg.PlanningScene,\n",
    "                                         queue_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "lang": "en"
   },
   "outputs": [],
   "source": [
    "from move_base_msgs.msg import MoveBaseAction, MoveBaseGoal\n",
    "from geometry_msgs.msg import PoseStamped, Point , Quaternion\n",
    "from actionlib_msgs.msg import GoalStatus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pose_tray_1\\n\\nframe_id: \"odom\"\\npose: \\n  position: \\n    x: 2.07474262655\\n    y: -0.463993086819\\n    z: 0.470428742931\\n  orientation: \\n    x: 0.787825948964\\n    y: -0.583793844356\\n    z: 0.156526059701\\n    w: 0.118383335252'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"pose_tray_1\n",
    "\n",
    "frame_id: \"odom\"\n",
    "pose: \n",
    "  position: \n",
    "    x: 2.07474262655\n",
    "    y: -0.463993086819\n",
    "    z: 0.470428742931\n",
    "  orientation: \n",
    "    x: 0.787825948964\n",
    "    y: -0.583793844356\n",
    "    z: 0.156526059701\n",
    "    w: 0.118383335252\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='start'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goal_x , goal_y,goal_yaw= kl_mess1# 1.04,0.3,1.57   #Known location mess 1\n",
    " \n",
    "\n",
    "scene.remove_world_object()\n",
    "#Takeshi neutral\n",
    "move_hand(0)\n",
    "arm.set_named_target('go')\n",
    "arm.go()\n",
    "head.set_named_target('neutral')\n",
    "head.go()\n",
    "move_base_goal(goal_x,goal_y,goal_yaw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "head_val=head.get_current_joint_values()\n",
    "head_val[0]=np.deg2rad(0)\n",
    "head_val[1]=np.deg2rad(-30)\n",
    "head.go(head_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_floor():\n",
    "    image_data = rgbd.get_image()\n",
    "    points_data = rgbd.get_points()\n",
    "\n",
    "    P1 = point_2D_3D(points_data, -1, -200)\n",
    "    P2 = point_2D_3D(points_data, -1, 200)\n",
    "    P3 = point_2D_3D(points_data, -150, -320)\n",
    "\n",
    "    V1 = P1 - P2\n",
    "    V2 = P3 - P2\n",
    "    nx, ny, nz = np.cross(V2, V1)\n",
    "    print('look at the phi angle  in normal vector', np.rad2deg(cart2spher(nx, ny, nz))[2] - 90)\n",
    "    trans, rot = listener.lookupTransform('/map', '/head_rgbd_sensor_gazebo_frame', rospy.Time(0))\n",
    "    euler = tf.transformations.euler_from_quaternion(rot)\n",
    "    print(np.rad2deg(euler)[1], ' if this degree is not the same as head tilt plane was not found')\n",
    "       \n",
    "    mask = np.zeros((image_data.shape))\n",
    "    plane_mask = np.zeros((image_data.shape[0], image_data.shape[1]))\n",
    "    mask[:, :, 0] = points_data['x'] - P1[0]\n",
    "    mask[:, :, 1] = points_data['y'] - P1[1]\n",
    "    mask[:, :, 2] = points_data['z'] - P1[2]\n",
    "    \n",
    "    for i in range (image_data.shape[0]):\n",
    "        for j in range (image_data.shape[1]):\n",
    "            plane_mask[i, j] = -np.dot(np.asarray((nx, ny, nz, )), mask[i, j])\n",
    "    plane_mask = plane_mask - np.min(plane_mask)\n",
    "    plane_mask = plane_mask * 256 / np.max(plane_mask)\n",
    "    plane_mask.astype('uint8')\n",
    "\n",
    "    ret, thresh = cv2.threshold(plane_mask, 3, 255, 0)\n",
    "\n",
    "    cv2_img = plane_mask.astype('uint8')\n",
    "    img = plane_mask.astype('uint8')\n",
    "    _, contours, hierarchy = cv2.findContours(thresh.astype('uint8'), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    i = 0\n",
    "    cents = []\n",
    "    for i, contour in enumerate(contours):\n",
    "        area = cv2.contourArea(contour)\n",
    "        \n",
    "        if area > 50 and area < 50000 :                        \n",
    "            boundRect = cv2.boundingRect(contour)            \n",
    "            img = cv2.rectangle(img, (boundRect[0], boundRect[1]), (boundRect[0] + boundRect[2], boundRect[1] + boundRect[3]), (255, 0, 0), 2)\n",
    "            # calculate moments for each contour\n",
    "            xyz = []\n",
    "                \n",
    "            for jy in range (boundRect[0], boundRect[0] + boundRect[2]):\n",
    "                for ix in range(boundRect[1], boundRect[1] + boundRect[3]):\n",
    "                    xyz.append(np.asarray((points_data['x'][ix, jy], points_data['y'][ix, jy], points_data['z'][ix, jy])))\n",
    "            xyz = np.asarray(xyz)\n",
    "            cent = xyz.mean(axis = 0)\n",
    "            \n",
    "            cents.append(cent)\n",
    "\n",
    "            M = cv2.moments(contour)\n",
    "            # calculate x,y coordinate of center\n",
    "            cX = int(M[\"m10\"] / M[\"m00\"])\n",
    "            cY = int(M[\"m01\"] / M[\"m00\"])\n",
    "            cv2.circle(img, (cX, cY), 5, (255, 255, 255), -1)\n",
    "            cv2.putText(img, \"centroid_\" + str(i) + \"_\" + str(cX) + ',' + str(cY), (cX - 25, cY - 25), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 255, 255), 2)\n",
    "    cents = np.asarray(cents)    \n",
    "    return cents  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "global name 'point_2D_3D' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-23cd680f7d9d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msegment_floor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-25-b445dfeca219>\u001b[0m in \u001b[0;36msegment_floor\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mpoints_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrgbd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_points\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mP1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpoint_2D_3D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoints_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mP2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpoint_2D_3D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoints_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mP3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpoint_2D_3D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoints_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m320\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: global name 'point_2D_3D' is not defined"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARN] [1621442285.967532, 1684.659000]: Inbound TCP/IP connection failed: connection from sender terminated before handshake header received. 0 bytes were received. Please check sender for additional details.\n"
     ]
    }
   ],
   "source": [
    " cents=segment_floor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "move_base_goal(goal_x,goal_y,goal_yaw)\n",
    "head_val=head.get_current_joint_values()\n",
    "head_val[0]=np.deg2rad(0)\n",
    "head_val[1]=np.deg2rad(-45)\n",
    "head.go(head_val)\n",
    "\n",
    "trans , rot = listener.lookupTransform('/map', '/head_rgbd_sensor_gazebo_frame', rospy.Time(0))\n",
    "\n",
    "euler=tf.transformations.euler_from_quaternion(rot)\n",
    "\n",
    "trans, euler\n",
    "cents=segment_floor()\n",
    "static_tf_publish(cents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "publish_scene()\n",
    "arm.go(arm_grasp_floor)\n",
    "move_hand(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " cents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_cents=[]\n",
    "for i,cent in enumerate(cents):\n",
    "    trans_map,_= listener.lookupTransform('/map', 'static'+str(i),rospy.Time(0))\n",
    "    trans_cents.append(trans_map)\n",
    "        \n",
    "\n",
    "np.linalg.norm(np.asarray(trans_cents)- trans , axis=1)\n",
    "closest_cent=np.argmin(np.linalg.norm(np.asarray(trans_cents)- trans , axis=1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.asarray(trans_cents).T[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_hand,rot_hand= listener.lookupTransform('/hand_palm_link', 'static'+str(closest_cent),rospy.Time(0))\n",
    "trans_hand,rot_hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wb=whole_body.get_current_joint_values()\n",
    "wb[0]+=trans_hand[2]-.1\n",
    "wb[1]+=trans_hand[1]\n",
    "whole_body.go(wb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "closest_cent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_hand,rot_hand= listener.lookupTransform('/hand_palm_link', 'static'+str(closest_cent),rospy.Time(0))\n",
    "trans_hand,rot_hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wb=whole_body.get_current_joint_values()\n",
    "wb[0]+=trans_hand[2]-.05\n",
    "wb[1]+=trans_hand[1]\n",
    "whole_body.go(wb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_hand,rot_hand= listener.lookupTransform('/hand_palm_link', 'static'+str(closest_cent),rospy.Time(0))\n",
    "trans_hand,rot_hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "move_hand(0)\n",
    "ungrasped=[-0.00047048998088961014,\n",
    " -0.03874743486886725,\n",
    " -0.04825256513113274,\n",
    " 0.038463464485261056,\n",
    " -0.03874743486886725]\n",
    "grasped=[0.12814103131904275,\n",
    " -0.30672794406396453,\n",
    " 0.21972794406396456,\n",
    " 0.13252877558892262,\n",
    " -0.30672794406396453]\n",
    "a=gripper.get_current_joint_values()\n",
    "if     np.linalg.norm(a-np.asarray(grasped))  >  (np.linalg.norm(a-np.asarray(ungrasped))):\n",
    "    print ('grasp seems to have failed')\n",
    "else:\n",
    "    print('super primitive fgrasp detector points towards succesfull ')\n",
    "    wb=whole_body.get_current_joint_values()\n",
    "    wb[0]+=trans_hand[2]-.3\n",
    "    \n",
    "    whole_body.go(wb)\n",
    "a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#move_hand(0)\n",
    "#Takeshi neutral\n",
    "arm.set_named_target('go')\n",
    "arm.go()\n",
    "head.set_named_target('neutral')\n",
    "head.go()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goal_x , goal_y,goal_yaw=  kl_tray  #1.84,0.0,-90  #Known location tray 1\n",
    "move_base_goal(goal_x,goal_y,-90)\n",
    "publish_scene()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arm.set_joint_value_target(arm_ready_to_place)\n",
    "arm.go()\n",
    "\n",
    "wb=whole_body.get_current_joint_values()\n",
    "wb[0]+=-0.45\n",
    "wb[4]+=-.3\n",
    "whole_body.set_joint_value_target(wb)\n",
    "whole_body.go()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "move_hand(1)\n",
    "\n",
    "wb=whole_body.get_current_joint_values()\n",
    "wb[0]+=0.3\n",
    "\n",
    "whole_body.set_joint_value_target(wb)\n",
    "whole_body.go()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#REPEAT AS LONG AS THERE ARE GRASPABLE OBJECTS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='repeat'></a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene.remove_world_object()\n",
    "goal_x,goal_y,goal_yaw=kl_table1\n",
    "move_hand(0)\n",
    "#Takeshi neutral\n",
    "arm.set_named_target('go')\n",
    "arm.go()\n",
    "head.set_named_target('neutral')\n",
    "head.go()\n",
    "move_base_goal(goal_x+.4,goal_y,goal_yaw)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#moveit\n",
    "#MOVE IT MUST BE RUNNING. DECLARE A HEAD POSE\n",
    "head_val=head.get_current_joint_values()\n",
    "head_val[0]=np.deg2rad(0)\n",
    "head_val[1]=np.deg2rad(-45)\n",
    "#WATCH OUT FOR JOINTS LIMITS (exorcist joke)\n",
    "#plan and execute target pose\n",
    "head.set_joint_value_target(head_val)\n",
    "head.go()\n",
    "### GET TF (REFERENCE FRAME FOR XTION SENSOR )\n",
    "trans , rot = listener.lookupTransform('/map', '/head_rgbd_sensor_gazebo_frame', rospy.Time(0))\n",
    "\n",
    "euler=tf.transformations.euler_from_quaternion(rot)\n",
    "\n",
    "trans, euler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cents=segment_table2(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "static_tf_publish(cents)\n",
    "cents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_cents=[]\n",
    "for i,cent in enumerate(cents):\n",
    "    trans_map,_= listener.lookupTransform('/map', 'static'+str(i),rospy.Time(0))\n",
    "    trans_cents.append(trans_map)\n",
    "        \n",
    "\n",
    "np.linalg.norm(np.asarray(trans_cents)- trans , axis=1)\n",
    "closest_cent=np.argmin(np.linalg.norm(np.asarray(trans_cents)- trans , axis=1))\n",
    "\n",
    "print(closest_cent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.04,0.3,1.57   #Known location mess 1\n",
    "kl_table2= [0 , 1.29,90] \n",
    "kl_table1= [1.04 , 1.29,90] \n",
    "goal_x , goal_y,goal_yaw= kl_table2\n",
    "\n",
    "#Takeshi neutral\n",
    "move_hand(0)\n",
    "arm.set_named_target('go')\n",
    "arm.go()\n",
    "move_base_goal(goal_x ,goal_y,goal_yaw)\n",
    "head_val=head.get_current_joint_values()\n",
    "head_val[0]=np.deg2rad(0)\n",
    "head_val[1]=np.deg2rad(-35)\n",
    "\n",
    "head.go(head_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cents=segment_table2()\n",
    "static_tf_publish(cents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wb=whole_body.get_current_joint_values()\n",
    "wb[3]+=.2\n",
    "whole_body.go(wb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "publish_scene()\n",
    "move_hand(1)\n",
    "\n",
    "#arm.set_joint_value_target(arm_grasp_from_above)\n",
    "#arm.set_joint_value_target(arm_grasp_floor)\n",
    "arm.set_joint_value_target(arm_grasp_table)\n",
    "arm.go()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_hand,rot_hand= listener.lookupTransform('/hand_palm_link', 'static0',rospy.Time(0))\n",
    "trans_hand,rot_hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wb=whole_body.get_current_joint_values()\n",
    "wb[0]+=trans_hand[2]-.07\n",
    "wb[1]+=trans_hand[1]\n",
    "wb[3]+=trans_hand[0]+.1\n",
    "whole_body.go(wb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_hand,rot_hand= listener.lookupTransform('/hand_palm_link', 'static0',rospy.Time(0))\n",
    "trans_hand,rot_hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wb=whole_body.get_current_joint_values()\n",
    "wb[0]+=trans_hand[2]-.07\n",
    "wb[1]+=trans_hand[1]\n",
    "wb[3]+=trans_hand[0]\n",
    "whole_body.go(wb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_hand,rot_hand= listener.lookupTransform('/hand_palm_link', 'static0',rospy.Time(0))\n",
    "trans_hand,rot_hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene.remove_world_object()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wb=whole_body.get_current_joint_values()\n",
    "wb[0]+=trans_hand[2]-.07\n",
    "wb[1]+=trans_hand[1]\n",
    "wb[3]+=trans_hand[0]\n",
    "whole_body.go(wb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "move_hand(0)\n",
    "ungrasped=[-0.00047048998088961014,\n",
    " -0.03874743486886725,\n",
    " -0.04825256513113274,\n",
    " 0.038463464485261056,\n",
    " -0.03874743486886725]\n",
    "grasped=[0.12814103131904275,\n",
    " -0.30672794406396453,\n",
    " 0.21972794406396456,\n",
    " 0.13252877558892262,\n",
    " -0.30672794406396453]\n",
    "a=gripper.get_current_joint_values()\n",
    "if     np.linalg.norm(a-np.asarray(grasped))  >  (np.linalg.norm(a-np.asarray(ungrasped))):\n",
    "    print ('grasp seems to have failed')\n",
    "else:\n",
    "    print('assuming succesful grasp')\n",
    "    wb=whole_body.get_current_joint_values()\n",
    "    wb[0]+=-0.2\n",
    "    wb[3]+=0.2\n",
    "    whole_body.set_joint_value_target(wb)\n",
    "    whole_body.go()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "publish_scene()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#move_hand(0)\n",
    "#Takeshi neutral\n",
    "arm.set_named_target('go')\n",
    "arm.go()\n",
    "head.set_named_target('neutral')\n",
    "head.go()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goal_x , goal_y,goal_yaw=  kl_box1  #1.84,0.0,-90  #Known location tray 1\n",
    "move_base_goal(goal_x,goal_y,-90)\n",
    "publish_scene()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arm.set_joint_value_target(arm_ready_to_place)\n",
    "arm.go()\n",
    "\n",
    "wb=whole_body.get_current_joint_values()\n",
    "wb[0]+=-0.6\n",
    "wb[4]+=-.3\n",
    "whole_body.set_joint_value_target(wb)\n",
    "whole_body.go()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "move_hand(1)\n",
    "\n",
    "wb=whole_body.get_current_joint_values()\n",
    "wb[0]+=0.3\n",
    "\n",
    "whole_body.set_joint_value_target(wb)\n",
    "whole_body.go()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[START](#start)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[REPEAT](#repeat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Run again the appropriate blocks to try to look for legos on the way\n",
    "\n",
    "\n",
    "###CAn you navigate through?\n",
    "\n",
    "### Can we pick em up?\n",
    "\n",
    "\n",
    "#PLEASE TRY THINGS HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "wb=whole_body.get_current_joint_values()\n",
    "wb[0]+=-0.2\n",
    "wb[3]+=0.2\n",
    "whole_body.set_joint_value_target(wb)\n",
    "whole_body.go()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "pose_goal=whole_body.get_current_pose()\n",
    "pose_goal.pose.position.x = xyz_map[0]\n",
    "pose_goal.pose.position.y = xyz_map[1]\n",
    "pose_goal.pose.position.z = xyz_map[2]+.06#.0155\n",
    "whole_body.set_pose_target(pose_goal)\n",
    "whole_body.go()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"a=arm.get_current_pose()\n",
    "a.pose.position.z=xyz_map[0]\n",
    "a.pose.position.z=xyz_map[1]\n",
    "a.pose.position.z=0.05\n",
    "arm.set_pose_target(a)\n",
    "succ=arm.go()\n",
    "succ\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "move_hand(0)\n",
    "#Takeshi neutral\n",
    "arm.set_named_target('go')\n",
    "arm.go()\n",
    "head.set_named_target('neutral')\n",
    "head.go()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### rubbish from here on.... \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_body.set_joint_value_target(p)\n",
    "whole_body.go()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pose_goal=whole_body.get_current_pose()\n",
    "pose_goal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "move_hand(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_body.clear_pose_targets()\n",
    "pose_goal=whole_body.get_current_pose()\n",
    "pose_goal.pose.position.x = xyz_map[0]\n",
    "pose_goal.pose.position.y = xyz_map[1]\n",
    "pose_goal.pose.position.z = xyz_map[2]+.16\n",
    "whole_body.set_pose_target(pose_goal)\n",
    "whole_body.set_goal_tolerance(.001)\n",
    "whole_body.allow_looking(True)\n",
    "\n",
    "whole_body.go()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(15):\n",
    "    whole_body.set_pose_target(pose_goal)\n",
    "    whole_body.go()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "move_hand(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    #whole_body.set_pose_target(pose_goal)\n",
    "    whole_body.go()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "move_hand(0)\n",
    "#Takeshi neutral\n",
    "arm.set_named_target('go')\n",
    "arm.go()\n",
    "head.set_named_target('neutral')\n",
    "head.go()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#Takeshi neutral\n",
    "arm.set_named_target('go')\n",
    "arm.go()\n",
    "head.set_named_target('neutral')\n",
    "head.go()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "arm.set_joint_value_target(arm_grasp_floor)\n",
    "arm.go()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "arm.set_joint_value_target(arm_train_pose)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arm.go()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=arm.get_current_joint_values()\n",
    "a[0]=-.3\n",
    "#a[-3]=-0.5*np.pi\n",
    "#arm.set_joint_value_target(a)\n",
    "#arm.go()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "move_hand(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=arm.get_current_joint_values()\n",
    "\n",
    "a[0]+=.1\n",
    "\n",
    "arm.set_joint_value_target(a)\n",
    "arm.go()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "arm.set_joint_value_target(a)\n",
    "arm.go()\n",
    "#move_hand(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=arm.get_current_pose()\n",
    "euler=tf.transformations.euler_from_quaternion((a.pose.orientation.x,a.pose.orientation.y,a.pose.orientation.z,a.pose.orientation.w))\n",
    "euler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MOVE IT MUST BE RUNNING. DECLARE A HEAD POSE\n",
    "head_val=head.get_current_joint_values()\n",
    "head_val[0]=np.deg2rad(0)\n",
    "head_val[1]=np.deg2rad(-45)\n",
    "#WATCH OUT FOR JOINTS LIMITS (exorcist joke)\n",
    "#plan and execute target pose\n",
    "head.set_joint_value_target(head_val)\n",
    "head.go()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_body.get_current_joint_values()[:3] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_body.get_active_joints()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "np.isclose(np.abs(cart2spher(nx,ny,nz))[2]-90 , 1.05   ,.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.isclose(np.abs(np.rad2deg(cart2spher(nx,ny,nz))[2]-90),np.abs(np.rad2deg(euler)[1]),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene.remove_world_object()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.transformations.quaternion_from_euler(0,np.pi*.5,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gripper.get_active_joints()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.04864392144339025,\n",
       " -0.10001174078352928,\n",
       " 0.01301174078352929,\n",
       " 0.09013803031711731,\n",
       " -0.10001174078352928]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cuv=gripper.get_current_joint_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gripper.get_current_joint_values()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gripper.allow_replanning()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gripper.get_current_joint_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gripper.clear_pose_targets()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gripper.get_current_pose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'grasped' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-53d1a9bac916>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgripper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_current_joint_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mif\u001b[0m     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrasped\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;34m>\u001b[0m  \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mungrasped\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'grasp seems to have failed'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'grasped' is not defined"
     ]
    }
   ],
   "source": [
    "a=gripper.get_current_joint_values()\n",
    "if     np.linalg.norm(a-np.asarray(grasped))  >  (np.linalg.norm(a-np.asarray(ungrasped))):\n",
    "    print ('grasp seems to have failed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "super primitive fgrasp detector points towards succesfull \n"
     ]
    }
   ],
   "source": [
    "\n",
    "ungrasped=[-0.00047048998088961014,\n",
    " -0.03874743486886725,\n",
    " -0.04825256513113274,\n",
    " 0.038463464485261056,\n",
    " -0.03874743486886725]\n",
    "\"\"\"grasped=[0.12814103131904275,\n",
    " -0.30672794406396453,\n",
    " 0.21972794406396456,\n",
    " 0.13252877558892262,\n",
    " -0.30672794406396453]\n",
    "\"\"\"\n",
    "grasped=[0.0432034, -0.1143983,  0.0273983,  0.0940839, -0.1143983]\n",
    "a=gripper.get_current_joint_values()\n",
    "if     np.linalg.norm(a-np.asarray(grasped))  >  (np.linalg.norm(a-np.asarray(ungrasped))):\n",
    "    print ('grasp seems to have failed')\n",
    "else:\n",
    "    print('super primitive fgrasp detector points towards succesfull ')\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "cuv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.0432034, -0.1143983,  0.0273983,  0.0940839, -0.1143983])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cuv=np.asarray(gripper.get_current_joint_values())\n",
    "cuv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.080051  ,  0.19618064, -0.19618064, -0.03978544,  0.19618064])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cuv-grasped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hand_l_spring_proximal_joint',\n",
       " 'hand_motor_joint',\n",
       " 'hand_r_spring_proximal_joint']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gripper.get_active_joints()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "move_hand(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  },
  "nbTranslate": {
   "displayLangs": [
    "ja"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "ja",
   "targetLang": "en",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
